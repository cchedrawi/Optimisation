# Optimisation
In this project, the focus revolves around solving optimization problems, particularly addressing distinct scenarios. The first scenario in the project involves implementing a gradient descent algorithm for solving an optimization problem. The algorithm has a fixed step size, terminates when the norm of the current gradient falls below a specified threshold (epsilon), and returns the list of iterates. The project then transitions to a different optimization problem, the lasso problem, in which the Proximal gradient algorithm is implemented to find the minimizer. Lastly, the third scenario tackles the basic pursuit problem using the ADMM algorithm, defining a function to find the minimizer and subsequently comparing estimated solutions with different regularization values concerning the true solution. Overall, the project explores various optimization algorithms and techniques for different problem formulations, providing insights into their performance and characteristics.
